#!/usr/bin/env python3

import argparse
import sys
import os
import requests
from datetime import datetime
import json
import logging

from .common_utils import *
from .github_utils import *
from .analyzer import RepoAnalyzer

# í¬ë§· ìƒìˆ˜
FORMAT_TABLE = "table"
FORMAT_TEXT = "text"
FORMAT_CHART = "chart"
FORMAT_ALL = "all"

VALID_FORMATS = [FORMAT_TABLE, FORMAT_TEXT, FORMAT_CHART, FORMAT_ALL]
VALID_FORMATS_DISPLAY = ", ".join(VALID_FORMATS)

# ì¹œì ˆí•œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•  ArgumentParser í´ë˜ìŠ¤
class FriendlyArgumentParser(argparse.ArgumentParser):
    def error(self, message: str) -> None:
        if '--format' in message:
            # --format ì˜µì…˜ì—ì„œë§Œ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©ì ì •ì˜
            logging.error(f"âŒ ì¸ì ì˜¤ë¥˜: {message}")
            logging.error(f"ì‚¬ìš© ê°€ëŠ¥í•œ --format ê°’: {VALID_FORMATS_DISPLAY}")
        else:
            super().error(message)
        sys.exit(2)

def parse_arguments() -> argparse.Namespace:
    """ì»¤ë§¨ë“œë¼ì¸ ì¸ìë¥¼ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜"""
    parser = FriendlyArgumentParser(
        prog="python -m reposcore",
        usage=(
            "python -m reposcore [-h] [owner/repo ...] "
            "[--output dir_name] "
            f"[--format {{{VALID_FORMATS_DISPLAY}}}] "
            "[--check-limit] "
            "[--user-info path]"
        ),
        description="ì˜¤í”ˆ ì†ŒìŠ¤ ìˆ˜ì—…ìš© ë ˆí¬ì§€í† ë¦¬ì˜ ê¸°ì—¬ë„ë¥¼ ë¶„ì„í•˜ëŠ” CLI ë„êµ¬",
        add_help=False
    )
    parser.add_argument(
        "-h", "--help",
        action="help",
        help="ë„ì›€ë§ í‘œì‹œ í›„ ì¢…ë£Œ"
    )
    # ì €ì¥ì†Œ ì¸ìë¥¼ í•˜ë‚˜ ì´ìƒ ë°›ë„ë¡ nargs="+"ë¡œ ë³€ê²½
    parser.add_argument(
        "repository",
        type=str,
        nargs="+",
        metavar="owner/repo",
        help="ë¶„ì„í•  GitHub ì €ì¥ì†Œë“¤ (í˜•ì‹: 'ì†Œìœ ì/ì €ì¥ì†Œ'). ì—¬ëŸ¬ ì €ì¥ì†Œì˜ ê²½ìš° ê³µë°± í˜¹ì€ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="results",
        metavar="dir_name",
        help="ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: 'results')"
    )
    parser.add_argument(
        "--format",
        choices=VALID_FORMATS,
        nargs='+',
        default=[FORMAT_ALL],
        metavar=f"{{{VALID_FORMATS_DISPLAY}}}",
        help =  f"ê²°ê³¼ ì¶œë ¥ í˜•ì‹ ì„ íƒ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥, ì˜ˆ: --format {FORMAT_TABLE} {FORMAT_CHART}) (ê¸°ë³¸ê°’:'{FORMAT_ALL}')"
    )
    parser.add_argument(
        "--grade",
        action="store_true",
        help="ì°¨íŠ¸ì— ë“±ê¸‰ í‘œì‹œ"
    )
    parser.add_argument(
        "--use-cache",
        action="store_true",
        help="participants ë°ì´í„°ë¥¼ ìºì‹œì—ì„œ ë¶ˆëŸ¬ì˜¬ì§€ ì—¬ë¶€ (ê¸°ë³¸: APIë¥¼ í†µí•´ ìƒˆë¡œ ìˆ˜ì§‘)"
    )
    parser.add_argument(
        "--token",
        type=str,
        help="API ìš”ì²­ ì œí•œ í•´ì œë¥¼ ìœ„í•œ ê¹ƒí—ˆë¸Œ ê°œì¸ ì•¡ì„¸ìŠ¤ í† í°"
    )
    parser.add_argument(
        "--check-limit",
        action="store_true",
        help="í˜„ì¬ GitHub API ìš”ì²­ ê°€ëŠ¥ íšŸìˆ˜ì™€ ì „ì²´ í•œë„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
    )
    parser.add_argument(
        "--user-info",
        type=str,
        help="ì‚¬ìš©ì ì •ë³´ íŒŒì¼ì˜ ê²½ë¡œ"
    )
    parser.add_argument(
        "--theme", "-t",
        choices=["default", "dark"],
        default="default",
        help="í…Œë§ˆ ì„ íƒ (default ë˜ëŠ” dark)"
    )
    return parser.parse_args()

def merge_participants(
    overall: dict[str, dict[str, int]],
    new_data: dict[str, dict[str, int]]
) -> dict[str, dict[str, int]]:
    """ë‘ participants ë”•ì…”ë„ˆë¦¬ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤."""
    for user, activities in new_data.items():
        if user not in overall:
            overall[user] = activities.copy()
        else:
            # ê° í•­ëª©ë³„ë¡œ í™œë™ìˆ˜ë¥¼ ëˆ„ì í•©ì‚°í•©ë‹ˆë‹¤.
            for key, value in activities.items():
                overall[user][key] = overall[user].get(key, 0) + value
    return overall


def main() -> None:
    """Main execution function"""
    args = parse_arguments()
    github_token = args.token
    if not args.token:
        github_token = os.getenv('GITHUB_TOKEN')
    elif args.token == '-':
        github_token = sys.stdin.readline().strip()

    if github_token and len(github_token) != 0:
        validate_token(github_token)

    # --check-limit ì˜µì…˜ ì²˜ë¦¬: ì´ ì˜µì…˜ì´ ìˆìœ¼ë©´ repository ì¸ì ì—†ì´ ì‹¤í–‰ë¨.
    if args.check_limit:
        check_rate_limit(token=github_token)
        sys.exit(0)

   # --user-info ì˜µì…˜ìœ¼ë¡œ ì§€ì •ëœ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€, JSON íŒŒì‹±ì´ ê°€ëŠ¥í•œì§€ ê²€ì¦
    if args.user_info:
        # 1) íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not os.path.isfile(args.user_info):
            logging.error("âŒ ì‚¬ìš©ì ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        # 2) JSON ë¬¸ë²• ì˜¤ë¥˜ í™•ì¸
        try:
            with open(args.user_info, "r", encoding="utf-8") as f:
                user_info = json.load(f)
        except json.JSONDecodeError:
            logging.error("âŒ ì‚¬ìš©ì ì •ë³´ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
            sys.exit(1)
    else:
        user_info = None

    repositories: list[str] = args.repository
    # ì‰¼í‘œë¡œ ì—¬ëŸ¬ ì €ì¥ì†Œê°€ ì…ë ¥ëœ ê²½ìš° ë¶„ë¦¬
    final_repositories = list(dict.fromkeys(
        [r.strip() for repo in repositories for r in repo.split(",") if r.strip()]
    ))

    # ê° ì €ì¥ì†Œ ìœ íš¨ì„± ê²€ì‚¬
    for repo in final_repositories:
        if not validate_repo_format(repo):
            logging.error(f"ì˜¤ë¥˜: ì €ì¥ì†Œ '{repo}'ëŠ” 'owner/repo' í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆ) 'oss2025hnu/reposcore-py'")
            sys.exit(1)
        if not check_github_repo_exists(repo):
            logging.warning(f"ì…ë ¥í•œ ì €ì¥ì†Œ '{repo}'ê°€ ê¹ƒí—ˆë¸Œì— ì¡´ì¬í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ.")
            sys.exit(1)

    logging.info(f"ì €ì¥ì†Œ ë¶„ì„ ì‹œì‘: {', '.join(final_repositories)}")

    overall_participants = {}
    
    #ì €ì¥ì†Œë³„ë¡œ ë¶„ì„ í›„ 'ê°œë³„ ê²°ê³¼'ë„ ì €ì¥í•˜ê¸°
    for repo in final_repositories:
        logging.info(f"ë¶„ì„ ì‹œì‘: {repo}")

        analyzer = RepoAnalyzer(repo, token=github_token, theme=args.theme)
        repo_aggregator = RepoAnalyzer(repo, token=github_token, theme=args.theme)

        # ì €ì¥ì†Œë³„ ìºì‹œ íŒŒì¼ ìƒì„± (ì˜ˆ: cache_oss2025hnu_reposcore-py.json)
        cache_file_name = f"cache_{repo.replace('/', '_')}.json"
        cache_path = os.path.join(args.output, cache_file_name)

        os.makedirs(args.output, exist_ok=True)

        cache_update_required = os.path.exists(cache_path) and analyzer.is_cache_update_required(cache_path)

        if args.use_cache and os.path.exists(cache_path) and not cache_update_required:
            logging.info(f"âœ… ìºì‹œ íŒŒì¼({cache_file_name})ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ìºì‹œì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
            with open(cache_path, "r", encoding="utf-8") as f:
                cached_json = json.load(f)
                analyzer.participants = cached_json['participants']
                analyzer.previous_create_at = cached_json['update_time']
        else:
            if args.use_cache and cache_update_required:
                logging.info(f"ğŸ”„ ë¦¬í¬ì§€í† ë¦¬ì˜ ìµœê·¼ ì´ìŠˆ ìƒì„± ì‹œê°„ì´ ìºì‹œíŒŒì¼ì˜ ìƒì„± ì‹œê°„ë³´ë‹¤ ìµœê·¼ì…ë‹ˆë‹¤. GitHub APIë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
            else:
                logging.info(f"ğŸ”„ ìºì‹œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê±°ë‚˜ ìºì‹œ íŒŒì¼({cache_file_name})ì´ ì—†ìŠµë‹ˆë‹¤. GitHub APIë¡œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
            analyzer.collect_PRs_and_issues()
            if not getattr(analyzer, "_data_collected", True):
                logging.error("âŒ GitHub API ìš”ì²­ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ íŒŒì¼ì„ ìƒì„±í•˜ì§€ ì•Šê³  ì¢…ë£Œí•©ë‹ˆë‹¤.")
                logging.error("â„¹ï¸ ì¸ì¦ ì—†ì´ ì‹¤í–‰í•œ ê²½ìš° ìš”ì²­ íšŸìˆ˜ ì œí•œ(403)ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. --token ì˜µì…˜ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”.")
                sys.exit(1)
            with open(cache_path, "w", encoding="utf-8") as f:
                json.dump({'update_time':analyzer.previous_create_at, 'participants': analyzer.participants}, f, indent=2, ensure_ascii=False)

        try:
            # 1) ì‚¬ìš©ì ì •ë³´ ë¡œë“œ (ì—†ìœ¼ë©´ None)
            user_info = json.load(open(args.user_info, "r", encoding="utf-8")) \
                if args.user_info and os.path.exists(args.user_info) else None

            # 2) ë¯¸ë¦¬ ìƒì„±í•´ ë‘” repo_aggregatorì— ì°¸ê°€ì ë°ì´í„° í• ë‹¹
            repo_aggregator.participants = analyzer.participants

            # ìŠ¤ì½”ì–´ ê³„ì‚°
            repo_scores = repo_aggregator.calculate_scores(user_info)

            # ì¶œë ¥ í˜•ì‹
            formats = set(args.format)
            if FORMAT_ALL in formats:
                formats = {FORMAT_TABLE, FORMAT_TEXT, FORMAT_CHART}

            # ì €ì¥ì†Œë³„ í´ë” ìƒì„± (owner/repo -> owner_repo)
            repo_safe_name = repo.replace('/', '_')
            repo_output_dir = os.path.join(args.output, repo_safe_name)
            os.makedirs(repo_output_dir, exist_ok=True)

            # 1) CSV í…Œì´ë¸” ì €ì¥
            if FORMAT_TABLE in formats:
                table_path = os.path.join(repo_output_dir, "score.csv")
                repo_aggregator.generate_table(repo_scores, save_path=table_path)
                repo_aggregator.generate_count_csv(repo_scores, save_path=table_path)
                logging.info(f"[ê°œë³„ ì €ì¥ì†Œ] CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {table_path}")

            # 2) í…ìŠ¤íŠ¸ í…Œì´ë¸” ì €ì¥
            if FORMAT_TEXT in formats:
                txt_path = os.path.join(repo_output_dir, "score.txt")
                repo_aggregator.generate_text(repo_scores, txt_path)
                logging.info(f"[ê°œë³„ ì €ì¥ì†Œ] í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {txt_path}")

            # 3) ì°¨íŠ¸ ì´ë¯¸ì§€ ì €ì¥
            if FORMAT_CHART in formats:
                chart_filename = "chart_grade.png" if args.grade else "chart.png"
                chart_path = os.path.join(repo_output_dir, chart_filename)
                repo_aggregator.generate_chart(repo_scores, save_path=chart_path, show_grade=args.grade)
                logging.info(f"[ê°œë³„ ì €ì¥ì†Œ] ì°¨íŠ¸ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {chart_path}")

        except Exception as e:
            logging.error(f"ì €ì¥ì†Œë³„ ê²°ê³¼ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

        overall_participants = merge_participants(overall_participants, analyzer.participants)
        logging.info(f"ë¶„ì„ ì™„ë£Œ: {repo}")
    # ë³‘í•©ëœ ë°ì´í„°ë¥¼ ê°€ì§€ê³  í†µí•© ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤.
    aggregator = RepoAnalyzer("multiple_repos", token=github_token, theme=args.theme)
    aggregator.participants = overall_participants

    try:
        user_info = json.load(open(args.user_info, "r", encoding="utf-8")) \
            if args.user_info and os.path.exists(args.user_info) else None
        # â€¦ì´ì œ ì—¬ê¸°ì— ë°”ë¡œ user_info ë³€ìˆ˜ ì‚¬ìš©â€¦
        repo_scores = repo_aggregator.calculate_scores(user_info)


        scores = aggregator.calculate_scores(user_info)
        formats = set(args.format)
        os.makedirs(args.output, exist_ok=True)

        if FORMAT_ALL in formats:
            formats = {FORMAT_TABLE, FORMAT_TEXT, FORMAT_CHART}

        # í†µí•© CSV
        if FORMAT_TABLE in formats:
            table_path = os.path.join(args.output, "score.csv")
            aggregator.generate_table(scores, save_path=table_path)
            aggregator.generate_count_csv(scores, save_path=table_path)
            logging.info(f"\n[í†µí•©] CSV ì €ì¥ ì™„ë£Œ: {table_path}")

        # í†µí•© í…ìŠ¤íŠ¸
        if FORMAT_TEXT in formats:
            txt_path = os.path.join(args.output, "score.txt")
            aggregator.generate_text(scores, txt_path)
            logging.info(f"\n[í†µí•©] í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {txt_path}")

        # í†µí•© ì°¨íŠ¸
        if FORMAT_CHART in formats:
            chart_filename = "chart_grade.png" if args.grade else "chart.png"
            chart_path = os.path.join(args.output, chart_filename)
            aggregator.generate_chart(scores, save_path=chart_path, show_grade=args.grade)
            logging.info(f"\n[í†µí•©] ì°¨íŠ¸ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {chart_path}")

    except Exception as e:
        logging.error(f"Error: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
